# Face Classification

## Overview
Latest version of our face classification is done by using transfer learning methods using pre-trained model MobileNetV2. It receives `RGB` images with shape (224, 224, 3) and predict the label. The output is categorical whic are 5 classes such as `correctly masked`, `no mask`, `uncovered chin`, `uncovered nose`, and `uncovered nose and mouth`. Previous versions includes using `MobileNetV2`, `MobileNetV3Large`, and also multi-class dataset.

## Directories Stucture
There are `Preprocessing`, `Modelling`, and `Saved_Models` subdirectories.
1. `Preprocessing` includes notebooks for extracting, preprocessing, and arranging datasets.
    1. [`Extract_Dataset.ipynb`](./Preprocessing/Extract_Dataset.ipynb) includes codes to extract [MaskedFace-Net dataset](https://github.com/cabani/MaskedFace-Net) and also combining [2nd](https://www.kaggle.com/omkargurav/face-mask-dataset) and [3rd](https://www.kaggle.com/prithwirajmitra/covid-face-mask-detection-dataset) datasets.
    1. [`arrange_CMFD_dataset.ipynb`](./Preprocessing/arrange_CMFD_dataset.ipynb),
    [`arrange_no_mask_dataset.ipynb`](./Preprocessing/arrange_no_mask_dataset.ipynb) and
    [`Arrange_IMFD_Images.ipynb`](./Preprocessing/Arrange_IMFD_Images.ipynb)
    arranges MaskedFace-Net dataset to directory structure suitable for [`ImageDataGenerator.flow_from_directory()`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory).
1. `Modelling` includes notebooks for building, training, and evaluating machine learning models.
    1. [`MobileNet_without_retrain.ipynb`](./Modelling/MobileNet_without_retrain.ipynb) includes codes to use `MobileNetV3Large` for transfer learning without retraining MobileNetV3Large's weights.
    1. [`MobileNetV2_retrain.ipynb`](./Modelling/MobileNetV2_retrain.ipynb) includes codes to use `MobilenetV2` for transfer learning.
    1. [`MobileNetV3_retrain.ipynb`](./Modelling/MobileNetV3_retrain.ipynb) includes codes to use `MobileNetV3Large` for transfer learning with various scenarios of retrain and dataset.
1. `Saved_Models` includes saved model files to be used in back-end app.

## Research History
### Dataset History
We first used [MaskedFace-Net dataset](https://github.com/cabani/MaskedFace-Net) which consists of 2 classes, `CMFD` (Correctly Masked) and `IMFD` (Incorrectly Masked). The images are faces of people patched with generated medical masks, __not real masks__. The IMFD images can be further splited into three classes, `uncovered chin`, `uncovered nose`, and `uncovered nose and chin`. We also combine it with [Flickr Faces HQ dataset](https://github.com/NVlabs/ffhq-dataset) for `no mask` faces. Thus we had 5 labels for this combined dataset which can be found [here](https://drive.google.com/drive/folders/1e6dsErnWnZ-ZMsk5HqGw6PUS-YgaUZXZ?usp=sharing).

After facing overfitting, due to the dataset only contains single variant of mask and all of them are generated by computer, we switch to new dataset. [Face mask dataset by omkargurav](https://www.kaggle.com/omkargurav/face-mask-dataset) contains more diverse masks and also different image shapes. This dataset improves prediction on new images, especially with diverse face masks. We further tried [the third dataset by prithwirajmitra](https://www.kaggle.com/prithwirajmitra/covid-face-mask-detection-dataset) and combine it with the second dataset. The combined dataset can be found [here](https://drive.google.com/drive/folders/1NvGlWbR7O0nZnI1CJXWcHZ3b_P3YExXj?usp=sharing).

### Model History
We first tried `transfer learning` using MobileNet. We tried `MobileNetV2` and `MobileNetV3Large` with various scenarios. All of them overfits on the training and fails to predict new images correctly. The most frequent problem we found is the training and validation `accuracy` and `loss` are high on training, but when we evaluate afterward the model predicts all images as the same label, even on training and validation datasets.

We then tried creating custom `CNN` model in hope having a better performance. It did much better than previous MobileNets, as it didn't fall into overfitting. But as the first dataset only contains images with uniform generated masks, it failed to predict random mask faces. When we use 2nd and 3rd datasets, we gain improvement on predictions on new images. But, for this scenario, the model can only classifying two classes which are `correctly masked` and `no mask` classes.

For the last trial, we decided to try make a model that can classify 5 classes. These classes are divided to be `correctly masked`, `no mask`, `uncovered chin`, `uncovered nose`, and `uncovered nose and mouth`. For this scenario, we used [MaskedFace-Net dataset](https://github.com/cabani/MaskedFace-Net) and combine with [Flickr Faces HQ dataset](https://github.com/NVlabs/ffhq-dataset). To obtain a good model then we use transfer learning method using pre-trained model MobileNetV2 and add some layer such as `Conv2D Layer` and `Dropout Layer`. Finally, those layer can bring the model to avoid overfitting and obtain good accuracy for training, validation, and testing. This model also can classify all 5 classes.

### Latest Datasets and Models used
The latest model used for classification is `MobileNetV2_retrain_best_model.h5`, trained using combined [MaskedFace-Net dataset](https://github.com/cabani/MaskedFace-Net) and [Flickr Faces HQ dataset](https://github.com/NVlabs/ffhq-dataset) for 8 epochs.

## Flow of Program
Training
1. Open image dataset using [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory).
1. Create the model.
1. Train the model using previous generator.
1. Evaluate the model using compiled metrics.

Inference
1. Open test image using [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory).
1. Load the model (if not created yet, or if not continuing directly from training).
1. Execute predict on the model using the generator.
1. Post-process the probability predictions into labels.

## Getting Started
### Prerequisites
We need to have `Python 3` and `Jupyter` on the environment where you'd like to run these notebooks. We used `Google Colaboratory` for researching on all these notebooks. We also need to install external packages that are imported inside each notebook, including, but not limited to `tensorflow`, `numpy`, `matplotlib`, and others.

### Run notebooks
Run the notebook on prepared environment. Each notebook can be run independently.

## Notes
- It is still unknown why MobileNets yield good results on training, but fail on evaluation, and even fail on predicting training set.

## References
- Cabani, A., Hammoudi, K., Benhabiles, H., &amp; Melkemi, M. (2020). MaskedFace-Net – A dataset of correctly/incorrectly masked face images in the context of COVID-19. Smart Health, 19, 100144. https://doi.org/10.1016/j.smhl.2020.100144
- Hammoudi, K., Cabani, A., Benhabiles, H., &amp; Melkemi, M. (2020). Validating the correct wearing of protection mask by taking a selfie: design of a mobile application "CheckYourMask" to limit the spread of COVID-19. Computer Modeling in Engineering &amp; Sciences, 124(3), 1049–1059. https://doi.org/10.32604/cmes.2020.011663
- Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., &amp; Adam, H. (2017, April 17). MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. arXiv.org. https://arxiv.org/abs/1704.04861
- Karras, T., Laine, S., &amp; Aila, T. (2019, February 6). A Style-Based Generator Architecture for Generative Adversarial Networks. arXiv.org. https://arxiv.org/abs/1812.04948

- [https://towardsdatascience.com/transfer-learning-using-mobilenet-and-keras-c75daf7ff299](https://towardsdatascience.com/transfer-learning-using-mobilenet-and-keras-c75daf7ff299)

## Licenses
The [MaskedFace-Net dataset](https://github.com/cabani/MaskedFace-Net) is under the license of [Creative Commons BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). We also refer the first 2 papers for using this dataset as stated in its [README.md file](https://github.com/cabani/MaskedFace-Net/blob/master/README.md).

The [Flickr Faces HQ dataset](https://github.com/NVlabs/ffhq-dataset) is also made available under the [Creative Commons BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. We also refer the paper by Tero Karras, Samuli Laine, Timo Aila for using this dataset as stated in its [README.md file](https://github.com/NVlabs/ffhq-dataset/blob/master/README.md).

## Contributors
- [Kc-codetalker](https://github.com/Kc-codetalker)
- [mohfaisal25](https://github.com/mohfaisal25)